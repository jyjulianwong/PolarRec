# Evaluation

This directory contains modules used for the quantitative evaluation process of the project. Running the `if __name__ == "__main__"` section of each `.py` file (except `sample_resources.py`) calculates an overall evaluation metric for the recommendation algorithm. For each metric, the recommendation algorithm is run multiple times using a different sample target academic resource each time, and the average of all the runs is used as the final overall metric value.

# Directories and files

| File                      | Description                                                                                                                                                                                                                                           |
|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `classification.py`       | Calculates the macro- and micro-classification accuracies of the algorithm, i.e. how many of the top recommended resources belong in the same subject area(s) as the target.                                                                          |
| `corpus_coverage.py`      | Calculates the proportion of out-of-vocabulary words the KeywordRanker model does not recognise amongst the titles and abstracts of the list of sample resources.                                                                                     |
| `keyword_extraction.py`   | Calculates the keyword extraction accuracy of the algorithm, i.e. how many of the top keywords extracted from the target resource match the pre-defined keywords set by the author / academic database.                                               |
| `performance.py`          | Calculates the mean processing time and mean peak memory usage for a single request to the algorithm.                                                                                                                                                 |
| `performance_profiler.py` | A section of sample code that can be run by the cProfile library for performance profiling. The code simulates the pre-loading of the KeywordRanker model and the processing of a single recommendation request.                                      |
| `recommendation.py`       | Calculates the recommendation accuracy of the algorithm. This uses the Semantic Scholar Recommendations API (S2R) as a gold standard, and compares how many of the top recommended resources generated by our algorithm match those generated by S2R. |
| `sample_resources.py`     | Custom library for collecting sample resource metadata from academic databases, and for saving and loading sample resource metadata to and from persistent JSON files.                                                                                |